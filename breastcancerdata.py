# -*- coding: utf-8 -*-
"""BreastCancerData.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gOmDZAuEl71ZnKynB4RsyXD35FAZX9nl
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import matplotlib.pyplot as plt
# % matplotlib inline
import statsmodels.api as sm
import numpy as np
import seaborn as sns

from sklearn.datasets import load_breast_cancer

data = load_breast_cancer()

print(data.keys())

data.data.shape

print(data.feature_names)

data_df = pd.DataFrame(data.data)
data_df.head()

data_df.columns = data.feature_names
data_df.head()

data_df["cancer"] = data.target
data_df.head()

data_df.describe()

data_df.isna().sum()

data_df.info()

data_df.dtypes

data_df1 = data_df.iloc[:,0:10]
data_df2 = data_df.iloc[:,10:20]
data_df3 = data_df.iloc[:,20:30]

data_df1.hist(xlabelsize=8,ylabelsize=8,bins=6,figsize=(10,8))
plt.tight_layout()
data_df2.hist(xlabelsize=8,ylabelsize=8,bins=6,figsize=(10,8))
plt.tight_layout()
data_df3.hist(xlabelsize=8,ylabelsize=8,bins=6,figsize=(10,8))
plt.tight_layout()
plt.show()

sns.heatmap(data_df.corr(), cmap="Greens")

plt.figure(figsize=(8,4))
sns.countplot(data_df['cancer'] , palette='RdBu')

# Drop all worst columns
cols = ['worst radius', 'worst texture','worst perimeter','worst area','worst smoothness','worst compactness',
        'worst concavity','worst concave points','worst symmetry','worst fractal dimension']
data_df = data_df.drop(cols,axis=1)

# drop all columns related to "perimeter" and "area" attributes
cols = ['mean perimeter','perimeter error','mean area','area error']
data_df = data_df.drop(cols,axis=1)

# lastly, drop all columns related to the "concavity" and "concave points" attribute
cols = ['mean concavity','mean concave points','concavity error','concave points error',]
data_df = data_df.drop(cols,axis=1)

data_df.columns

sns.heatmap(data_df.corr(), cmap="Greens")

from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split

X = data_df.drop(columns=["cancer"])
y = data_df[["cancer"]]

# Calculate Normalisation
x = y-np.min(y)/np.max(y)-np.min(y).values
x

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.2)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

lr = LogisticRegression()

lr.fit(X_train, y_train)

y_pred = lr.predict(X_test)

y_pred

y_pred_nominal = ["0" if x < 0.5 else "1" for x in y_pred]
y_pred_nominal[0:6]

y_test.cancer

(y_pred == y_test.cancer).mean()

from sklearn.metrics import accuracy_score, confusion_matrix

accuracy_score(y_test.cancer, y_pred)